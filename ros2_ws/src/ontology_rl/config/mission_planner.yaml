# Mission Planner RL Training Configuration
# Level 1: Strategic mission planning (10s decision horizon)

# Environment settings
env_id: 'FlybyMissionPlanner-v0'
env_kwargs:
  max_steps: 1000
  num_waypoints: 5
  world_size: 100.0
  battery_return_threshold: 20.0

# Algorithm: PPO (good for discrete action spaces)
algorithm: 'PPO'

# Training parameters
total_timesteps: 100000
n_envs: 1

# PPO hyperparameters
learning_rate: 0.0001
n_steps: 1024
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01
vf_coef: 0.5
max_grad_norm: 0.5

# Network architecture
policy_kwargs:
  net_arch:
    - 128
    - 128

# Reproducibility
seed: 42

# Logging
tensorboard_log: './logs/mission_planner'
log_interval: 10
verbose: 1

# Checkpointing
save_freq: 10000
save_path: './models/mission_planner'

# Evaluation
eval_freq: 5000
n_eval_episodes: 10

# Ontology constraints
ontology:
  geofence_radius: 100.0
  min_altitude: 0.0
  max_altitude: 120.0
  battery_critical: 10.0
  battery_warning: 20.0
  nfz_regions:
    - center: [-50.0, 50.0]
      radius: 30.0
